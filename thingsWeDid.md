# Static-Site Deployer CLI - Progress Tracking

## âœ… Completed Steps

### Step 0 - Prep your workstation (Windows Edition)
- âœ… **Environment Check**: Confirmed PowerShell execution policy is `RemoteSigned`
- âœ… **Package Manager**: Chocolatey v2.2.2 already installed
- âœ… **Tools Inventory**: 
  - Python 3.12.1 âœ…
  - AWS CLI 2.15.15 âœ…
  - Node.js v20.10.0 âœ…
  - Git 2.42.0 âœ…
  - Terraform v1.12.2 âœ… (just installed)
  - jq âœ… (installed via Chocolatey)
- âœ… **Project Setup**: Created `static-site-deployer` directory
- âœ… **Git Init**: Git repository already initialized with main branch

### Step 1 - Python environment
- âœ… **Virtual Environment**: Created `.venv` using `python -m venv .venv`
- âœ… **Activation**: Activated virtual environment with `.venv\Scripts\Activate.ps1`
- âœ… **Python Version**: Confirmed Python 3.12.1 in virtual environment
- âœ… **Gitignore Setup**: Created comprehensive `.gitignore` to prevent committing virtual environment files
- âœ… **Virtual Environment Recreation**: Recreated `.venv` after cleanup to avoid Git issues

### Step 2 - Basic repo scaffold
- âœ… **Folder Structure**: Created `cli/`, `infra/`, `.github/workflows/`, `site-sample/` directories
- âœ… **Python Package**: Created `cli/__init__.py` to make cli a Python package
- âœ… **Documentation**: Created `README.md` and `REQUIREMENTS.md` files
- âœ… **Sample Site**: Created `site-sample/index.html` with "Hello world" content
- âœ… **Git Commit**: Committed scaffold with message "chore: scaffold repo"

### Step 3 - AWS account bootstrap
- âœ… **AWS Authentication**: Initially logged in as `ryan_admin` IAM user
- âœ… **IAM User Setup**: Created new IAM user `ryan_dev_home` with appropriate permissions
- âœ… **Access Keys**: Generated programmatic access keys for CLI usage
- âœ… **Profile Configuration**: Set up AWS CLI profile `ryan_dev_home` with credentials
- âœ… **Authentication Test**: Confirmed `ryan_dev_home` profile is working correctly
- âœ… **S3 Bucket**: Created `ryan-static-site-deployer-tf-state` for Terraform state storage (in correct account 296950653587)
- âœ… **DynamoDB Table**: Created `tf-state-lock` table for Terraform state locking
- âœ… **Backend Config**: Created `infra/backend.tf` with remote state configuration
- âœ… **Git Commit**: Committed backend configuration with message "infra: add remote backend"

### Step 4 - Terraform installation
- âœ… **Terraform Install**: Installed Terraform v1.12.2 via Chocolatey
- âœ… **Environment Setup**: Imported Chocolatey profile module for PATH updates
- âœ… **Version Test**: Confirmed Terraform is working correctly

### Step 5 - Create S3 bucket & CloudFront (COMPLETED)
- âœ… **Terraform Infrastructure**: Created `infra/main.tf` with S3 bucket and CloudFront distribution
- âœ… **Terraform Plan**: Successfully planned infrastructure with 6 resources
- âœ… **Terraform Apply**: Successfully created all AWS resources
- âœ… **S3 Bucket**: `ryan-static-site-deployer` created with versioning and website hosting
- âœ… **CloudFront Distribution**: `E2U98SO9UWJ7JS` created with Origin Access Control
- âœ… **CloudFront URL**: `https://d2ckbhbg0ietbn.cloudfront.net`
- âœ… **S3 Website URL**: `ryan-static-site-deployer.s3-website-us-east-1.amazonaws.com`
- âœ… **S3 Bucket Policy**: Added policy to allow CloudFront access via Origin Access Control
- âœ… **CloudFront Access Fix**: Resolved "Access Denied" error by adding missing bucket policy

### Step 6 - IAM OIDC role (GitHub) (PENDING)
- ğŸ”„ **Next**: Create `infra/oidc.tf` for GitHub Actions OIDC role

### Step 7 - Local Secrets (COMPLETED)
- âœ… **Environment Variables**: Set up PowerShell environment variables
- âœ… **DEPLOY_BUCKET**: `ryan-static-site-deployer`
- âœ… **CF_DIST_ID**: `E2U98SO9UWJ7JS`
- âœ… **CF_URL**: `https://d2ckbhbg0ietbn.cloudfront.net`

### Step 8 - Python package skeleton (COMPLETED)
- âœ… **pyproject.toml**: Created with all required dependencies (boto3, click, tqdm, colorama)
- âœ… **Package Installation**: Successfully installed with `pip install -e .`
- âœ… **Console Script**: `deploy_site = "cli.main:cli"` configured

### Step 9 - CLI hash & upload logic (COMPLETED)
- âœ… **cli/hashutil.py**: Created file hash comparison utilities
- âœ… **cli/uploader.py**: Created S3 upload logic with delta detection
- âœ… **Hash Comparison**: MD5 hash comparison with S3 ETags
- âœ… **Progress Bar**: TQDM integration for file processing
- âœ… **Colored Output**: Colorama integration for cross-platform colors

### Step 10 - CloudFront invalidation logic (COMPLETED)
- âœ… **cli/invalidate.py**: Created CloudFront invalidation logic
- âœ… **Path Normalization**: Automatic `/` prefix for CloudFront paths
- âœ… **Batch Processing**: Handles >1000 paths with multiple invalidations
- âœ… **Invalidation Tracking**: Wait for invalidation completion

### Step 11 - Entry-point script (COMPLETED)
- âœ… **cli/main.py**: Created main CLI entry point with Click framework
- âœ… **CLI Flags**: Implemented all required flags (--bucket, --dist-id, --dry-run, --wait)
- âœ… **Environment Variables**: Support for DEPLOY_BUCKET and CF_DIST_ID env vars
- âœ… **Exit Codes**: Proper exit codes (0=success, 1=arg error, 2=AWS error)
- âœ… **Dry Run Mode**: Full dry-run implementation
- âœ… **Error Handling**: Comprehensive error handling and user feedback

## ğŸ”„ Current Status
- **Current Step**: Step 12 (Lighthouse manual sanity check)
- **Working Directory**: `C:\Users\Ryan\Desktop\Work\BriteSystems\DevOps\static-site-deployer`
- **Virtual Environment**: âœ… Active and working
- **AWS Profile**: `ryan_dev_home` configured and tested
- **Terraform**: âœ… Infrastructure created successfully
- **Python CLI**: âœ… Fully functional with all components
- **jq**: âœ… Installed and available
- **Documentation**: âœ… Updated README and created howTo.md

## ğŸ“‹ Next Steps (According to Plan)
1. **Step 12**: Lighthouse manual sanity check (in progress)
2. **Step 6**: Create IAM OIDC role for GitHub Actions (`infra/oidc.tf`)
3. **Step 13**: GitHub Secrets/Vars setup
4. **Step 14**: GitHub Actions workflow
5. **Step 15**: Push and test pipeline

## ğŸš€ CLI Testing Status
- âœ… **deploy_site --help**: Working
- âœ… **deploy_site site-sample --dry-run**: Working with AWS profile
- âœ… **deploy_site site-sample**: Working with actual deployment
- âœ… **Actual deployment**: Successfully deployed to CloudFront
- âœ… **CloudFront invalidation**: Working (ID: I3RQYWATE9JM8FE1ZCJVKF0TG3)
- âœ… **Hash comparison**: Working (skips unchanged files)
- âœ… **Error handling**: Working (403 errors handled properly with profile)

## ğŸ“š Documentation Status
- âœ… **README.md**: Updated with current progress and accurate information
- âœ… **howTo.md**: Created comprehensive build and usage guide
- âœ… **thingsWeDid.md**: Updated with current progress
- âœ… **PLAN.md**: Updated with .gitignore notes

## ğŸ› ï¸ Windows-Specific Adaptations Made
- Using PowerShell instead of bash
- Using `python -m venv` instead of pyenv
- Windows path separators (`\`)
- PowerShell environment variable syntax (`$env:VARIABLE_NAME`)
- Chocolatey package management
- AWS CLI profile configuration for Windows
- Chocolatey profile module import for PATH updates

## ğŸ” AWS Setup Notes
- **Account**: 296950653587 (correct account for IAM user)
- **IAM User**: ryan_dev_home (newly created)
- **Profile**: ryan_dev_home (configured in AWS CLI)
- **S3 Bucket**: ryan-static-site-deployer-tf-state (for Terraform state, in correct account)
- **DynamoDB Table**: tf-state-lock (for Terraform state locking)
- **Permissions**: Full access granted (`"Action": "*"`)

## ğŸ—ï¸ Infrastructure Architecture Explained

### Why Terraform Remote State?

**The Problem:**
- Terraform needs to remember what resources it created (S3 buckets, CloudFront, etc.)
- By default, Terraform stores this info in a local file called `terraform.tfstate`
- If you put this file in Git, you're storing sensitive info (resource IDs, etc.) in your repo
- If multiple people work on the project, they could overwrite each other's changes

**The Solution:**
- Store the state file in S3 (remote storage) instead of locally
- Use DynamoDB to "lock" the state so only one person can run Terraform at a time
- This way:
  - âœ… No sensitive files in Git
  - âœ… Team can collaborate safely
  - âœ… State is backed up in AWS
  - âœ… You can see what resources exist even if you delete your local files

**What we're building:**
```
Your Local Files â†’ Terraform â†’ AWS Resources
     â†“
Terraform State (stored in S3)
     â†“
Lock Table (DynamoDB prevents conflicts)
```

**So the S3 bucket is like a "memory bank" for Terraform to remember what it built.**

## ğŸš¨ Issues Resolved
- **Account Mismatch**: Bucket was created in wrong AWS account (471112835616 vs 296950653587)
- **State File Corruption**: Local state file had invalid JSON format
- **Backend Configuration Conflicts**: Multiple backend config changes causing initialization issues
- **Permission Issues**: 403 errors due to account ownership problems

---
*Last Updated: Step 5 - Terraform initialization successful with local state*
